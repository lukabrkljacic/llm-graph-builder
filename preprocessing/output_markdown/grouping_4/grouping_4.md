# Slide 1

# Description:
---
doc_title: "99P Modular and Adaptable Output Decomposition in Large Language Models"
page_index: 7
total_pages: 1
page_type: mixed
confidence_overall: 0.82
languages_detected: ["English"]
detected_sections: ["Theme Poster / Title", "Start / End / Director of Project / End-User / PIC / Collaborators", "A00", "Targets / Minimum Viable Prototype", "Recent Achievements", "Project Plan", "Background, Current Challenges and Barriers", "Our Focus", "This will be achieved by", "Expected Outcomes & Impact"]
figures_detected: 2
tables_detected: 0
equations_detected: 0
footnotes_detected: 0
watermarks_or_stamps: false
---

# Theme Poster: 99P Modular and Adaptable Output Decomposition in Large Language Models

---

**Start / End:** Apr 2025 – July 2025
**Director of Project:** Duane Detwiler
**End-User:** HG/HM (anticipate tools/infra for HG/HM)

**PIC:**
**Collaborators:** Ryan Lingo, Martin Arroyo, Luka Brkljacic, Ben Davis, Rajeev Chhajer, Nithin Santhanam

---

**A00**
Develop a framework that turns LLM outputs into clear, modular pieces, making them easy to understand, refine, and reuse.

---

## Targets / Minimum Viable Prototype

1) Modular output decomposition
2) Node-level editing
3) UI – Browser-based workspace
4) Dependency-aware updates
5) Selective reruns

---

## Recent Achievements

- Mapped out the key workflow from prompt to editable modules.
- Built a starter prompt set that encourages the model to label each section.
- Sketched interface wireframes and gathered initial feedback from researchers.

Papers: x1 planning x5 blogs
Patents: Not Applicable
HTF: Not Applicable

---

**Figure 1. Diagram (red-bordered schematic)**

- Visible elements:
  - Red border around a multi-layered diagram with nested boxes.
  - Inner boxes include a central colored box (yellow) and surrounding gray areas.
  - Several small rounded boxes on the right (colored purple/lilac).
  - Small green "sticky note" boxes near the bottom-right of the diagram.
  - A small title area at the top of the diagram (text [illegible]).
- Text inside diagram: [illegible] for most labels and inner text.
- Summary: Diagram shows nested contexts/modules and peripheral output parts, but specific node/edge labels are not legible.

---

## Project Plan

April → May → Jun → Jul

- Timeline graphic shows months April, May, Jun, Jul in a blue arrow sequence.
- Tasks shown aligned beneath timeline:
  - Task 1 under April
  - Task 2 under May
  - Task 3 spanning into June/July

**Figure 2. Project timeline (graphic)**
- Months: April, May, Jun, Jul (large arrows).
- Tasks: Task 1, Task 2, Task 3 (positioned under the respective months as above).

---

## Background, Current Challenges and Barriers

The Current Challenge: Monolithic & Inflexible LLM Outputs
LLM outputs for complex tasks are often monolithic. This structure hinders:
  o Understanding and verification
  o Iterative refinement
  o Adaption to new requirements

This research addresses the critical need for LLMs to produce inherently modular and adaptable outputs.

Our Focus: Enabling Modular & Adaptable Outputs
We are investigating methods to guide Large Language Models (LLMs) to generate outputs as a series of distinct, interconnected, and adaptable modules. Our goal is to develop methods for structured, editable, and reusable LLM responses.

This will be achieved by:
- Developing effective prompting and interaction strategies to structure outputs into logical modules.
- Exploring how LLMs can manage dependencies between these output modules.
- Employing a system framework that includes:
  - Context isolation for focused module generation.
  - Persistent memory for component management.
  - Collaborative interfaces for user interaction and refinement.

Expected Outcomes & Impact:
- Enhanced Clarity: Outputs become easier to understand, dissect, and debug.
- Improved Iterative Refinement: Users and LLMs can focus on specific parts of a solution more efficiently.
- Increased Adaptability: Solutions can be readily adjusted to new requirements by modifying or replacing modules.
- Better Human-AI Collaboration: Facilitates teamwork on distinct and verifiable components.
- Greater Reusability & Transparency: Output modules may be reused, leading to more controllable and maintainable AI solutions.

---

## Page artifacts
- Header: "Theme Poster: 99P Modular and Adaptable Output Decomposition in Large Language Models" (large centered title)
- TRL bar: numbered 1 through 9 (visual); TRL 5 highlighted in red.
- Page number: 7 (top-right)
- Footer: none legible beyond boxed sections described above.
- Watermark or stamp: none visible

## Lossy_Description
- Small diagram inside the red-bordered figure: most internal labels and node texts are illegible; could not transcribe exact node/edge names.
- Timeline graphic is schematic; exact task start/end horizontal positions approximated from visual alignment.

# Slide 2

# Description:
---
doc_title: "99P Modular and Adaptable Output Decomposition in Large Language Models"
page_index: 1
total_pages: 1
page_type: content
confidence_overall: 0.86
languages_detected: ["English"]
detected_sections: ["99P Modular and Adaptable Output Decomposition in Large Language Models", "1. Background", "2. Methods", "3. Findings", "99P Labs Team"]
figures_detected: 0
tables_detected: 0
equations_detected: 0
footnotes_detected: 0
watermarks_or_stamps: false
---

# 99P Modular and Adaptable Output Decomposition in Large Language Models

This project develops a framework
that breaks down LLM outputs into
clear, modular components, making
them easier to understand, edit, and
reuse. By enabling structured and
adaptable responses, it improves
clarity, flexibility, and collaboration
in AI-assisted work.

99P Labs Team:
- Ryan Lingo
- Martin Arroyo
- Luka Brkljacic
- Ben Davis
- Rajeev Chhajer
- Nithin Santhanam

## 1. Background
Large Language Models (LLMs) are powerful tools, but their outputs are often delivered as large, monolithic text blocks. This makes it difficult for users, especially researchers and developers, to understand, refine, or adapt the model's responses. These rigid outputs hinder critical tasks like verifying information, making iterative improvements, and adapting responses to changing needs.

This project tackles the need for LLMs to produce more modular and adaptable outputs by breaking down complex answers into manageable, structured components. The goal is to help users better understand, edit, and reuse model outputs.

## 2. Methods
The team is developing a framework that guides LLMs to generate outputs as a collection of clear, editable modules. These methods include:
- Prompting strategies to encourage the model to structure its responses into logical sections
- Dependency management tools to track relationships between modules
- A browser-based interface for users to interact with and refine individual parts of the output
- System components such as:
  - Context isolation for generating focused modules
  - Persistent memory to manage shared information across modules
  - Collaborative tools for refining outputs with user feedback

Initial prototypes include a modular output decomposition system, node-level editing features, and selective reruns of specific sections. Early work has produced wireframes, prompt templates, and initial user feedback.

## 3. Findings
Although still in development (through July 2025), early progress shows promise in transforming how LLM outputs are handled:
- Clarity: Modular outputs are easier to read, understand, and debug
- Efficiency: Users can refine specific sections without reworking the entire response
- Flexibility: Outputs can be adapted to new requirements by simply updating modules
- Collaboration: Clearly defined modules make it easier for humans and AI to work together
- Reusability: Modular design enables better versioning, tracking, and control of AI outputs

This work lays the foundation for more maintainable and human-aligned AI systems, particularly valuable in research environments that demand transparency and precision.

## Page artifacts
- Header: "99P Modular and Adaptable Output Decomposition in Large Language Models" (page title at top)
- Footer: none detected
- Page number: 1
- Watermark or stamp: none detected

## Lossy_Description
- Minor uncertainty in the exact spelling of the name "Luka Brkljacic" due to small font; transcribed as seen.