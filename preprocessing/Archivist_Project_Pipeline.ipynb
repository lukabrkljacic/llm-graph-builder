{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7aKzN5PDTfE"
   },
   "source": [
    "# 0. Install if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_4TUKm2DDMbc",
    "outputId": "579a0d17-1afc-437f-b52a-14c3e30e4990"
   },
   "outputs": [],
   "source": [
    "%pip install \"markitdown[all]\" openai pdf2image pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, basic definitions and option selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RAC62971\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from markitdown import MarkItDown\n",
    "from dotenv import load_dotenv\n",
    "from pdf2image import convert_from_path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the API key from the top-level .env file\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the model we want to use to convert the PNGs into Markdown\n",
    "LLM_MODEL = \"gpt-5-mini\"\n",
    "\n",
    "# Read in the system prompts\n",
    "sys_prompt_detailed = (Path.cwd() / \"system_prompts\" / \"system_prompt_detailed.md\").read_text(encoding=\"utf-8\")\n",
    "sys_prompt_summarized = (Path.cwd() / \"system_prompts\" / \"system_prompt_summarized.md\").read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Choose the system prompt you'd like to use. Detailed will attempt to keep as much of the original content\n",
    "# as possible, at the cost of speed and cost. Summarized will summarize much more of the content but it will\n",
    "# be fast and cost less to process the data\n",
    "sys_prompt_mode = \"detailed\" # can be 'detailed' or 'summarized'\n",
    "system_prompt = sys_prompt_detailed if sys_prompt_mode == \"detailed\" else sys_prompt_summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown conversion function\n",
    "All file types except for PowerPoint are converted directory into Markdown. PowerPoints are first converted into a PDF, which is then converted into PNGs, and finally those PNGs are converted into Markdown.\n",
    "\n",
    "Allowed file types: \n",
    "* PowerPoint\n",
    "    - pptx\n",
    "* Word\n",
    "    - docx\n",
    "* Excel\n",
    "    - xlsx\n",
    "    - xls\n",
    "    - csv\n",
    "* Text\n",
    "    - txt\n",
    "    - pdf\n",
    "    - html\n",
    "    - htm\n",
    "    - html_string\n",
    "    - log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALLLLLLLLLLLLLLLLLLLL OF THEMMMMMMMMMMMMMMMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_kind(kind: str) -> str:\n",
    "    if not kind:\n",
    "        raise ValueError(\"kind is required\")\n",
    "    return kind.lower().strip()\n",
    "\n",
    "\n",
    "DEFAULT_OUTPUT_DIRECTORIES = {\n",
    "    \"docx\": \"./output_docx\",\n",
    "    \"xlsx\": \"./output_xlsx\",\n",
    "    \"xls\": \"./output_xlsx\",\n",
    "    \"html\": \"./output_html\",\n",
    "    \"htm\": \"./output_html\",\n",
    "    \"txt\": \"./output_txt\",\n",
    "    \"log\": \"./output_txt\",\n",
    "    \"csv\": \"./output_csv\",\n",
    "    \"pdf\": \"./output_markdown\",\n",
    "    \"pptx\": \"./output_markdown\",\n",
    "    \"png\": \"./output_markdown\",\n",
    "    \"jpg\": \"./output_markdown\",\n",
    "    \"jpeg\": \"./output_markdown\",\n",
    "    \"html_string\": \"./output_html\",\n",
    "}\n",
    "\n",
    "DIRECT_MARKITDOWN_KINDS = {\"docx\", \"xlsx\", \"xls\", \"html\", \"htm\", \"txt\", \"log\", \"csv\"}\n",
    "IMAGE_KINDS = {\"png\", \"jpg\", \"jpeg\"}\n",
    "\n",
    "DEFAULT_PDF_DPI = 200\n",
    "DEFAULT_IMAGE_FORMAT = \"PNG\"\n",
    "\n",
    "\n",
    "def _resolve_output_dir(kind: str, override: Optional[Union[str, Path]]) -> Path:\n",
    "    if override is not None:\n",
    "        return Path(override)\n",
    "    try:\n",
    "        default = DEFAULT_OUTPUT_DIRECTORIES[kind]\n",
    "    except KeyError as exc:\n",
    "        raise ValueError(f\"No default output directory configured for kind '{kind}'\") from exc\n",
    "    return Path(default)\n",
    "\n",
    "\n",
    "def _build_markitdown_converter(\n",
    "    use_llm: bool,\n",
    "    llm_client,\n",
    "    llm_model: Optional[str],\n",
    "    llm_prompt: Optional[str],\n",
    "):\n",
    "    if use_llm:\n",
    "        if llm_client is None or llm_model is None:\n",
    "            raise ValueError(\"use_llm=True requires llm_client and llm_model\")\n",
    "        return MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)\n",
    "    return MarkItDown()\n",
    "\n",
    "\n",
    "def _write_markdown(text: str, out_dir: Path, base_name: str) -> Path:\n",
    "    out_path = out_dir / f\"{base_name}.md\"\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def _convert_html_string(converter: MarkItDown, html_value: str, out_dir: Path, base_name: str) -> Path:\n",
    "    result = converter.convert_html(html_value)\n",
    "    return _write_markdown(result.text_content or \"\", out_dir, base_name)\n",
    "\n",
    "\n",
    "def _convert_standard_file(\n",
    "    path: Path,\n",
    "    converter: MarkItDown,\n",
    "    out_dir: Path,\n",
    "    base_name: Optional[str],\n",
    ") -> Path:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Input file does not exist: {path}\")\n",
    "    result = converter.convert(str(path))\n",
    "    final_name = base_name or path.stem\n",
    "    return _write_markdown(result.text_content or \"\", out_dir, final_name)\n",
    "\n",
    "\n",
    "def _render_pdf_to_pngs(\n",
    "    pdf_path: Path,\n",
    "    image_dir: Path,\n",
    "    *,\n",
    "    dpi: int = DEFAULT_PDF_DPI,\n",
    "    fmt: str = DEFAULT_IMAGE_FORMAT,\n",
    "    poppler_path: Optional[Union[str, Path]] = None,\n",
    "    first_page: Optional[int] = None,\n",
    "    last_page: Optional[int] = None,\n",
    ") -> List[Path]:\n",
    "    image_dir.mkdir(parents=True, exist_ok=True)\n",
    "    poppler_dir = str(poppler_path) if poppler_path else os.getenv(\"POPPLER_PATH\")\n",
    "    images = convert_from_path(\n",
    "        str(pdf_path),\n",
    "        dpi=dpi,\n",
    "        first_page=first_page,\n",
    "        last_page=last_page,\n",
    "        poppler_path=poppler_dir,\n",
    "    )\n",
    "    start_index = first_page or 1\n",
    "    fmt_upper = fmt.upper()\n",
    "    suffix = fmt.lower()\n",
    "    saved: List[Path] = []\n",
    "    for offset, image in enumerate(images):\n",
    "        page_number = start_index + offset\n",
    "        out_path = image_dir / f\"page_{page_number:03}.{suffix}\"\n",
    "        image.save(out_path, fmt_upper)\n",
    "        saved.append(out_path)\n",
    "    return saved\n",
    "\n",
    "\n",
    "def _convert_images_to_markdown(\n",
    "    image_paths: Iterable[Path],\n",
    "    converter: MarkItDown,\n",
    "    out_dir: Path,\n",
    "    base_name: str,\n",
    "    *,\n",
    "    section_prefix: str = \"Image\",\n",
    ") -> Path:\n",
    "    ordered_images = [Path(p) for p in image_paths]\n",
    "    if not ordered_images:\n",
    "        raise RuntimeError(\"No images were produced for Markdown conversion\")\n",
    "\n",
    "    fragments: List[str] = []\n",
    "    failures: List[Tuple[Path, Exception]] = []\n",
    "    for idx, image_path in enumerate(ordered_images, start=1):\n",
    "        try:\n",
    "            result = converter.convert(str(image_path))\n",
    "        except Exception as exc:  # pragma: no cover - passthrough for runtime issues\n",
    "            failures.append((image_path, exc))\n",
    "            continue\n",
    "        content = (result.text_content or \"\").strip()\n",
    "        header = f\"# {section_prefix} {idx}\"\n",
    "        fragments.append(f\"{header}\n",
    "\n",
    "{content}\" if content else header)\n",
    "\n",
    "    if not fragments:\n",
    "        raise RuntimeError(\"Failed to generate Markdown from the rendered images\")\n",
    "\n",
    "    markdown_body = \"\n",
    "\n",
    "\".join(fragment.strip() for fragment in fragments if fragment).strip()\n",
    "    output_path = _write_markdown(markdown_body, out_dir, base_name)\n",
    "\n",
    "    if failures:\n",
    "        issues = \", \".join(f\"{path.name}: {exc}\" for path, exc in failures)\n",
    "        warnings.warn(\n",
    "            f\"Encountered {len(failures)} image conversion error(s) while building {output_path.name}: {issues}\",\n",
    "            RuntimeWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def _convert_pdf_pipeline(\n",
    "    pdf_path: Path,\n",
    "    converter: MarkItDown,\n",
    "    out_dir: Path,\n",
    "    base_name: Optional[str],\n",
    "    *,\n",
    "    dpi: int = DEFAULT_PDF_DPI,\n",
    "    fmt: str = DEFAULT_IMAGE_FORMAT,\n",
    "    poppler_path: Optional[Union[str, Path]] = None,\n",
    "    first_page: Optional[int] = None,\n",
    "    last_page: Optional[int] = None,\n",
    ") -> Path:\n",
    "    pdf_path = Path(pdf_path)\n",
    "    final_name = base_name or pdf_path.stem\n",
    "    png_root = Path(\"./output_pngs\") / final_name\n",
    "    if png_root.exists():\n",
    "        shutil.rmtree(png_root)\n",
    "    image_paths = _render_pdf_to_pngs(\n",
    "        pdf_path,\n",
    "        png_root,\n",
    "        dpi=dpi,\n",
    "        fmt=fmt,\n",
    "        poppler_path=poppler_path,\n",
    "        first_page=first_page,\n",
    "        last_page=last_page,\n",
    "    )\n",
    "    return _convert_images_to_markdown(image_paths, converter, out_dir, final_name, section_prefix=\"Page\")\n",
    "\n",
    "\n",
    "def _pptx_to_pdf(pptx_path: Path, output_dir: Path) -> Path:\n",
    "    pptx_path = Path(pptx_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_pdf = output_dir / f\"{pptx_path.stem}.pdf\"\n",
    "\n",
    "    try:\n",
    "        from pptx2pdf import convert as pptx2pdf_convert  # type: ignore\n",
    "    except ImportError:\n",
    "        pptx2pdf_convert = None\n",
    "\n",
    "    if pptx2pdf_convert is not None:\n",
    "        try:\n",
    "            pptx2pdf_convert(str(pptx_path), output_path=str(target_pdf))\n",
    "        except TypeError:\n",
    "            pptx2pdf_convert(str(pptx_path), output_dir=str(output_dir))\n",
    "        if target_pdf.exists():\n",
    "            return target_pdf\n",
    "\n",
    "    for cmd in (\"soffice\", \"libreoffice\"):\n",
    "        executable = shutil.which(cmd)\n",
    "        if not executable:\n",
    "            continue\n",
    "        subprocess.run(\n",
    "            [executable, \"--headless\", \"--convert-to\", \"pdf\", str(pptx_path), \"--outdir\", str(output_dir)],\n",
    "            check=True,\n",
    "        )\n",
    "        if target_pdf.exists():\n",
    "            return target_pdf\n",
    "\n",
    "    unoconv = shutil.which(\"unoconv\")\n",
    "    if unoconv:\n",
    "        subprocess.run([unoconv, \"-f\", \"pdf\", \"-o\", str(target_pdf), str(pptx_path)], check=True)\n",
    "        if target_pdf.exists():\n",
    "            return target_pdf\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Unable to convert PPTX to PDF. Install `pptx2pdf` or LibreOffice/Unoconv and ensure it is on your PATH.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_pptx_pipeline(\n",
    "    pptx_path: Path,\n",
    "    converter: MarkItDown,\n",
    "    out_dir: Path,\n",
    "    base_name: Optional[str],\n",
    "    **pdf_kwargs,\n",
    ") -> Path:\n",
    "    pptx_path = Path(pptx_path)\n",
    "    final_name = base_name or pptx_path.stem\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        pdf_path = _pptx_to_pdf(pptx_path, Path(tmp_dir))\n",
    "        return _convert_pdf_pipeline(pdf_path, converter, out_dir, final_name, **pdf_kwargs)\n",
    "\n",
    "\n",
    "def _convert_image_pipeline(\n",
    "    image_path: Path,\n",
    "    converter: MarkItDown,\n",
    "    out_dir: Path,\n",
    "    base_name: Optional[str],\n",
    ") -> Path:\n",
    "    image_path = Path(image_path)\n",
    "    final_name = base_name or image_path.stem\n",
    "    return _convert_images_to_markdown([image_path], converter, out_dir, final_name, section_prefix=\"Image\")\n",
    "\n",
    "\n",
    "def convert_to_markdown_file(\n",
    "    input_value: Union[str, Path],\n",
    "    kind: str,\n",
    "    use_llm: bool = False,\n",
    "    llm_client=None,\n",
    "    llm_model: Optional[str] = None,\n",
    "    llm_prompt: Optional[str] = None,\n",
    "    out_dir: Optional[Union[str, Path]] = None,\n",
    "    out_name: Optional[str] = None,\n",
    ") -> Path:\n",
    "    \"\"\"Convert supported inputs into Markdown files on disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_value:\n",
    "        For file-based kinds, pass a filesystem path. For ``html_string`` provide raw HTML.\n",
    "    kind:\n",
    "                One of {'docx', 'xlsx', 'xls', 'html', 'htm', 'txt', 'log', 'csv', 'pdf', 'pptx', 'png', 'jpg', 'jpeg', 'html_string'}.\n",
    "    use_llm, llm_client, llm_model, llm_prompt:\n",
    "        Forwarded to :class:`MarkItDown` when LLM-backed conversion is desired.\n",
    "    out_dir:\n",
    "        Optional override of the destination directory. Defaults to ``./output_<group>``.\n",
    "    out_name:\n",
    "        Optional base filename (without extension) for the generated Markdown.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Location of the primary Markdown file that was written.\n",
    "    \"\"\"\n",
    "    normalized_kind = _normalize_kind(kind)\n",
    "    if normalized_kind not in DEFAULT_OUTPUT_DIRECTORIES:\n",
    "        raise ValueError(f\"kind must be one of {sorted(DEFAULT_OUTPUT_DIRECTORIES)}\")\n",
    "\n",
    "    destination_dir = _resolve_output_dir(normalized_kind, out_dir)\n",
    "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    converter = _build_markitdown_converter(use_llm, llm_client, llm_model, llm_prompt)\n",
    "\n",
    "    if normalized_kind == \"html_string\":\n",
    "        if not out_name:\n",
    "            raise ValueError(\"out_name is required when kind='html_string'\")\n",
    "        return _convert_html_string(converter, str(input_value), destination_dir, out_name)\n",
    "\n",
    "    if normalized_kind in DIRECT_MARKITDOWN_KINDS:\n",
    "        return _convert_standard_file(Path(input_value), converter, destination_dir, out_name)\n",
    "\n",
    "    if normalized_kind == \"pdf\":\n",
    "        return _convert_pdf_pipeline(\n",
    "            Path(input_value),\n",
    "            converter,\n",
    "            destination_dir,\n",
    "            out_name,\n",
    "            poppler_path=os.getenv(\"POPPLER_PATH\"),\n",
    "        )\n",
    "\n",
    "    if normalized_kind == \"pptx\":\n",
    "        return _convert_pptx_pipeline(\n",
    "            Path(input_value),\n",
    "            converter,\n",
    "            destination_dir,\n",
    "            out_name,\n",
    "            dpi=DEFAULT_PDF_DPI,\n",
    "            fmt=DEFAULT_IMAGE_FORMAT,\n",
    "            poppler_path=os.getenv(\"POPPLER_PATH\"),\n",
    "        )\n",
    "\n",
    "    if normalized_kind in IMAGE_KINDS:\n",
    "        return _convert_image_pipeline(Path(input_value), converter, destination_dir, out_name)\n",
    "\n",
    "    raise ValueError(f\"Unsupported kind '{normalized_kind}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_MfmhYvDrM0"
   },
   "source": [
    "# 1. Convert PDF -> PNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-m4uQ17ERqT"
   },
   "source": [
    "Goes through a PDF and converts each page into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the POPPLER_PATH environment variable\n",
    "os.environ[\"POPPLER_PATH\"] = r\"C:\\Users\\RAC62971\\Downloads\\poppler-25.07.0\\Library\\bin\"\n",
    "\n",
    "def pdf_to_grouped_pngs(\n",
    "    pdf_path: Union[str, Path],\n",
    "    out_dir: Union[str, Path],\n",
    "    dpi: int = 200,\n",
    "    group_size: int = 1,\n",
    "    grouping_prefix: str = \"grouping\",\n",
    "    fmt: str = \"PNG\",\n",
    "    poppler_path: Optional[Union[str, Path]] = None,\n",
    "    first_page: Optional[int] = None,\n",
    "    last_page: Optional[int] = None,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Convert a PDF into per-page images and group them into subfolders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf_path : str | Path\n",
    "        Path to the input PDF, e.g. r\"C:\\\\...\\\\my.pdf\".\n",
    "    out_dir : str | Path\n",
    "        Output directory root where grouped folders will be created.\n",
    "    dpi : int, default 200\n",
    "        Render DPI for rasterization.\n",
    "    group_size : int, default 1\n",
    "        Number of pages per group folder. For example, 2 will place pages\n",
    "        1 and 2 into 'grouping_1', pages 3 and 4 into 'grouping_2', etc.\n",
    "    grouping_prefix : str, default \"grouping\"\n",
    "        Folder name prefix for each group.\n",
    "    fmt : str, default \"PNG\"\n",
    "        Image format to write. Common options are \"PNG\" and \"JPEG\".\n",
    "    poppler_path : str | Path | None\n",
    "        Path to Poppler bin directory on Windows if not on PATH.\n",
    "        Example: r\"C:\\\\tools\\\\poppler-24.08.0\\\\Library\\\\bin\"\n",
    "    first_page : int | None\n",
    "        Optional first page to convert (1-indexed).\n",
    "    last_page : int | None\n",
    "        Optional last page to convert (inclusive).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, List[str]]\n",
    "        Mapping of group folder name to list of saved image paths (strings).\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if group_size < 1:\n",
    "        raise ValueError(\"group_size must be >= 1\")\n",
    "\n",
    "    images = convert_from_path(\n",
    "        str(pdf_path),\n",
    "        dpi=dpi,\n",
    "        first_page=first_page,\n",
    "        last_page=last_page,\n",
    "        poppler_path=str(poppler_path) if poppler_path else None,\n",
    "    )\n",
    "\n",
    "    saved: Dict[str, List[str]] = {}\n",
    "    for i, img in enumerate(images, start=1 if not first_page else first_page):\n",
    "        # Compute 1-indexed group index\n",
    "        group_idx = (i - (first_page or 1)) // group_size + 1\n",
    "        group_dir = out_dir / f\"{grouping_prefix}_{group_idx}\"\n",
    "        group_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        page_basename = f\"page_{i:03}.{fmt.lower()}\"\n",
    "        out_path = group_dir / page_basename\n",
    "        img.save(out_path, fmt)\n",
    "        saved.setdefault(f\"{grouping_prefix}_{group_idx}\", []).append(str(out_path))\n",
    "\n",
    "    return saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grouping_1': ['output_pngs\\\\grouping_1\\\\page_001.png',\n",
       "  'output_pngs\\\\grouping_1\\\\page_002.png'],\n",
       " 'grouping_2': ['output_pngs\\\\grouping_2\\\\page_003.png',\n",
       "  'output_pngs\\\\grouping_2\\\\page_004.png'],\n",
       " 'grouping_3': ['output_pngs\\\\grouping_3\\\\page_005.png',\n",
       "  'output_pngs\\\\grouping_3\\\\page_006.png'],\n",
       " 'grouping_4': ['output_pngs\\\\grouping_4\\\\page_007.png',\n",
       "  'output_pngs\\\\grouping_4\\\\page_008.png'],\n",
       " 'grouping_5': ['output_pngs\\\\grouping_5\\\\page_009.png',\n",
       "  'output_pngs\\\\grouping_5\\\\page_010.png']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_to_grouped_pngs(\n",
    "    pdf_path=r\".\\input_data\\V2 - one-pagers with summaries- HRI-OH-99P Project Descriptions (1).pdf\",\n",
    "    out_dir=r\".\\output_pngs\",\n",
    "    dpi=200,\n",
    "    group_size=2,\n",
    "    grouping_prefix=\"grouping\",\n",
    "    poppler_path=os.environ[\"POPPLER_PATH\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBzF54RBEauR"
   },
   "source": [
    "# 2. Convert PNGs -> Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPbr2C9uEfuM",
    "outputId": "1589af9b-d7b8-4291-dd35-d1de73296f1e"
   },
   "outputs": [],
   "source": [
    "PNG_DIR = Path(\"./output_pngs\")\n",
    "OUT_DIR = Path(\"./output_markdown\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "image_converter = MarkItDown(\n",
    "    llm_client=client,\n",
    "    llm_model=LLM_MODEL,\n",
    "    llm_prompt=system_prompt\n",
    ")\n",
    "\n",
    "def _grouping_index(p: Path) -> int:\n",
    "    # Extract the integer from \"grouping_{number}\"\n",
    "    m = re.search(r\"grouping_(\\d+)$\", p.name)\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "def _sorted_imgs(imgs):\n",
    "    # Sort by any integer in filename, else lexicographic\n",
    "    def key_fn(p: Path):\n",
    "        m = re.findall(r\"\\d+\", p.stem)\n",
    "        return (int(m[-1]) if m else 0, p.name.lower())\n",
    "    return sorted(imgs, key=key_fn)\n",
    "\n",
    "# Ensure OUT_DIR exists\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Find all grouping_* directories at first level under PNG_DIR\n",
    "grouping_dirs = sorted([d for d in PNG_DIR.iterdir() if d.is_dir() and d.name.startswith(\"grouping_\")],\n",
    "                    key=_grouping_index)\n",
    "\n",
    "if not grouping_dirs:\n",
    "    print(f\"No grouping_* directories found in {PNG_DIR.resolve()}\")\n",
    "\n",
    "for tdir in grouping_dirs:\n",
    "    grouping_num = _grouping_index(tdir)\n",
    "    imgs = _sorted_imgs(list(tdir.glob(\"*.png\")))\n",
    "    if not imgs:\n",
    "        print(f\"Skipping {tdir.name} because it has no PNGs\")\n",
    "        continue\n",
    "\n",
    "    per_image_md = []\n",
    "    for i, img_path in enumerate(imgs, start=1):\n",
    "        try:\n",
    "            res = image_converter.convert(str(img_path))\n",
    "            per_image_md.append(f\"\\n\\n# Slide {i}\\n\\n\" + res.text_content.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not per_image_md:\n",
    "        print(f\"No markdown produced for {tdir.name}\")\n",
    "        continue\n",
    "\n",
    "    combined_image_md = \"\".join(per_image_md).strip()\n",
    "\n",
    "    # Write to OUT_DIR/grouping_{number}/<BASE_NAME>_grouping_{number}_{with|no}_llm.md\n",
    "    out_grouping_dir = OUT_DIR / f\"grouping_{grouping_num}\"\n",
    "    out_grouping_dir.mkdir(parents=True, exist_ok=True)\n",
    "    suffix = \"processed\"\n",
    "    combined_path = out_grouping_dir / f\"grouping_{grouping_num}.md\"\n",
    "    combined_path.write_text(combined_image_md, encoding=\"utf-8\")\n",
    "    print(\"Wrote:\", combined_path.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}