{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7aKzN5PDTfE"
      },
      "source": [
        "# 0. Install if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_4TUKm2DDMbc",
        "outputId": "579a0d17-1afc-437f-b52a-14c3e30e4990"
      },
      "outputs": [],
      "source": [
        "%pip install \"markitdown[all]\" openai pdf2image pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports, basic definitions and option selections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUQ97W8rD13A",
        "outputId": "23c821c1-2350-44c3-80f4-f031137124f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\RAC62971\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from markitdown import MarkItDown\n",
        "from dotenv import load_dotenv\n",
        "from pdf2image import convert_from_path\n",
        "from typing import Dict, List, Optional, Union, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load in the API key from the top-level .env file\n",
        "load_dotenv(Path.cwd().parent / \".env\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the model we want to use to convert the PNGs into Markdown\n",
        "LLM_MODEL = \"gpt-5-mini\"\n",
        "\n",
        "# Read in the system prompts\n",
        "sys_prompt_detailed = (Path.cwd() / \"system_prompts\" / \"system_prompt_detailed.md\").read_text(encoding=\"utf-8\")\n",
        "sys_prompt_summarized = (Path.cwd() / \"system_prompts\" / \"system_prompt_summarized.md\").read_text(encoding=\"utf-8\")\n",
        "\n",
        "# Choose the system prompt you'd like to use. Detailed will attempt to keep as much of the original content\n",
        "# as possible, at the cost of speed and cost. Summarized will summarize much more of the content but it will\n",
        "# be fast and cost less to process the data\n",
        "sys_prompt_mode = \"detailed\" # can be 'detailed' or 'summarized'\n",
        "system_prompt = sys_prompt_detailed if sys_prompt_mode == \"detailed\" else sys_prompt_summarized\n",
        "\n",
        "# Define input and output directories\n",
        "INPUT_BASE_DIR = Path(\"./input_data/not_processed\")\n",
        "OUTPUT_BASE_DIR = Path(\"./input_data/processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_markdown_file(\n",
        "    input_value: Union[str, Path],\n",
        "    kind: str,\n",
        "    use_llm: bool = False,\n",
        "    llm_client=None,\n",
        "    llm_model: Optional[str] = None,\n",
        "    llm_prompt: Optional[str] = None,\n",
        "    out_dir: Optional[Union[str, Path]] = None,\n",
        "    out_name: Optional[str] = None,\n",
        "    project_context: Optional[Dict] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Convert an input file or HTML string to Markdown using MarkItDown and write it to ./output_(file_type).\n",
        "\n",
        "    Parameters\n",
        "    - input_value\n",
        "      - For file-based kinds, pass a filesystem path.\n",
        "      - For 'html_string', pass a raw HTML string.\n",
        "    - kind: one of {'docx','xlsx','xls','html','htm','txt','log','csv','html_string'}\n",
        "    - use_llm: default False. If True, provide llm_client and llm_model.\n",
        "    - llm_client, llm_model, llm_prompt: forwarded to MarkItDown when use_llm=True\n",
        "    - out_dir: optional override of the output directory. Defaults to ./output_(group)\n",
        "    - out_name: optional base filename without extension. Defaults to input file stem when applicable.\n",
        "    - project_context: dict containing project metadata that gets added to markdown output\n",
        "\n",
        "    Returns\n",
        "    - Path to the written Markdown file.\n",
        "    \"\"\"\n",
        "    # 1) Normalize kind and choose default output directory bucket\n",
        "    k = kind.lower().strip()\n",
        "    allowed = {\"docx\", \"xlsx\", \"xls\", \"html\", \"htm\", \"txt\", \"log\", \"csv\", \"html_string\", \"png\", \"pptx\", \"pdf\"}\n",
        "    if k not in allowed:\n",
        "        raise ValueError(f\"kind must be one of {allowed}\")\n",
        "\n",
        "    if out_dir is None:\n",
        "        if k in {\"xlsx\", \"xls\"}:\n",
        "            out_dir = \"./output_xlsx\"\n",
        "        elif k in {\"html\", \"htm\", \"html_string\"}:\n",
        "            out_dir = \"./output_html\"\n",
        "        elif k in {\"txt\", \"log\"}:\n",
        "            out_dir = \"./output_txt\"\n",
        "        elif k == \"docx\":\n",
        "            out_dir = \"./output_docx\"\n",
        "        elif k == \"csv\":\n",
        "            out_dir = \"./output_csv\"\n",
        "        elif k in {\"png\", \"pptx\", \"pdf\"}:\n",
        "            out_dir = \"./output_images\"\n",
        "\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 2) Build MarkItDown converter\n",
        "    from markitdown import MarkItDown\n",
        "    if use_llm:\n",
        "        if llm_client is None or llm_model is None:\n",
        "            raise ValueError(\"use_llm=True requires llm_client and llm_model\")\n",
        "        converter = MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)\n",
        "    else:\n",
        "        converter = MarkItDown()\n",
        "\n",
        "    # 3) Convert depending on kind\n",
        "    if k == \"html_string\":\n",
        "        if not out_name:\n",
        "            raise ValueError(\"out_name is required when kind='html_string'\")\n",
        "        res = converter.convert_html(str(input_value))\n",
        "        base_name = out_name\n",
        "    else:\n",
        "        p = Path(input_value)\n",
        "        res = converter.convert(str(p))\n",
        "        base_name = out_name or p.stem\n",
        "\n",
        "    # 4) Add project context to beginning of Markdown output if provided\n",
        "    if project_context:\n",
        "        context_str = \"#### PROJECT CONTEXT\\n\"\n",
        "        for key, value in project_context.items():\n",
        "            context_str += f\"- **{key}:** {value}\\n\"\n",
        "        context_str += \"\\n\"\n",
        "        res.text_content = context_str + res.text_content\n",
        "        \n",
        "    # 5) Write markdown\n",
        "    out_path = out_dir / f\"{base_name}.md\"\n",
        "    out_path.write_text(res.text_content, encoding=\"utf-8\")\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Markdown conversion function\n",
        "All file types except for PowerPoint are converted directory into Markdown. PowerPoints are first converted into a PDF, which is then converted into PNGs, and finally those PNGs are converted into Markdown.\n",
        "\n",
        "Allowed file types: \n",
        "* PowerPoint\n",
        "    - pptx\n",
        "* Word\n",
        "    - docx\n",
        "* Excel\n",
        "    - xlsx\n",
        "    - xls\n",
        "    - csv\n",
        "* Text\n",
        "    - txt\n",
        "    - pdf\n",
        "    - html\n",
        "    - htm\n",
        "    - html_string\n",
        "    - log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_MfmhYvDrM0"
      },
      "source": [
        "# 1. Convert PDF -> PNGs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-m4uQ17ERqT"
      },
      "source": [
        "Goes through a PDF and converts each page into an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the POPPLER_PATH environment variable\n",
        "os.environ[\"POPPLER_PATH\"] = r\"C:\\\\Users\\\\RAC62971\\\\Downloads\\\\poppler-25.07.0\\\\Library\\\\bin\"\n",
        "\n",
        "def pdf_to_grouped_pngs(\n",
        "    pdf_path: Union[str, Path],\n",
        "    out_dir: Union[str, Path],\n",
        "    dpi: int = 200,\n",
        "    group_size: int = 1,\n",
        "    grouping_prefix: str = \"grouping\",\n",
        "    fmt: str = \"PNG\",\n",
        "    poppler_path: Optional[Union[str, Path]] = None,\n",
        "    first_page: Optional[int] = None,\n",
        "    last_page: Optional[int] = None,\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Convert a PDF into per-page images and group them into subfolders.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pdf_path : str | Path\n",
        "        Path to the input PDF, e.g. r\"C:\\\\...\\\\my.pdf\".\n",
        "    out_dir : str | Path\n",
        "        Output directory root where grouped folders will be created.\n",
        "    dpi : int, default 200\n",
        "        Render DPI for rasterization.\n",
        "    group_size : int, default 1\n",
        "        Number of pages per group folder. For example, 2 will place pages\n",
        "        1 and 2 into 'grouping_1', pages 3 and 4 into 'grouping_2', etc.\n",
        "    grouping_prefix : str, default \"grouping\"\n",
        "        Folder name prefix for each group.\n",
        "    fmt : str, default \"PNG\"\n",
        "        Image format to write. Common options are \"PNG\" and \"JPEG\".\n",
        "    poppler_path : str | Path | None\n",
        "        Path to Poppler bin directory on Windows if not on PATH.\n",
        "        Example: r\"C:\\\\tools\\\\poppler-24.08.0\\\\Library\\\\bin\"\n",
        "    first_page : int | None\n",
        "        Optional first page to convert (1-indexed).\n",
        "    last_page : int | None\n",
        "        Optional last page to convert (inclusive).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, List[str]]\n",
        "        Mapping of group folder name to list of saved image paths (strings).\n",
        "    \"\"\"\n",
        "    pdf_path = Path(pdf_path)\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if group_size < 1:\n",
        "        raise ValueError(\"group_size must be >= 1\")\n",
        "\n",
        "    images = convert_from_path(\n",
        "        str(pdf_path),\n",
        "        dpi=dpi,\n",
        "        first_page=first_page,\n",
        "        last_page=last_page,\n",
        "        poppler_path=str(poppler_path) if poppler_path else None,\n",
        "    )\n",
        "\n",
        "    saved: Dict[str, List[str]] = {}\n",
        "    for i, img in enumerate(images, start=1 if not first_page else first_page):\n",
        "        # Compute 1-indexed group index\n",
        "        group_idx = (i - (first_page or 1)) // group_size + 1\n",
        "        group_dir = out_dir / f\"{grouping_prefix}_{group_idx}\"\n",
        "        group_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        page_basename = f\"page_{i:03}.{fmt.lower()}\"\n",
        "        out_path = group_dir / page_basename\n",
        "        img.save(out_path, fmt)\n",
        "        saved.setdefault(f\"{grouping_prefix}_{group_idx}\", []).append(str(out_path))\n",
        "\n",
        "    return saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_project(project_name: str):\n",
        "    \"\"\"\n",
        "    Process an entire project directory.\n",
        "    \n",
        "    Args:\n",
        "        project_name (str): Name of the project directory\n",
        "    \"\"\"\n",
        "    print(f\"Processing project: {project_name}\")\n",
        "    \n",
        "    # Get input and output paths\n",
        "    project_input_dir = INPUT_BASE_DIR / project_name\n",
        "    project_output_dir = OUTPUT_BASE_DIR / project_name\n",
        "    \n",
        "    # Create output directory\n",
        "    project_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Read project metadata\n",
        "    metadata_path = project_input_dir / \"metadata.json\"\n",
        "    project_metadata = {}\n",
        "    if metadata_path.exists():\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            project_metadata = json.load(f)\n",
        "    \n",
        "    # Initialize client for LLM-based conversions\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    image_converter = MarkItDown(\n",
        "        llm_client=client,\n",
        "        llm_model=LLM_MODEL,\n",
        "        llm_prompt=system_prompt\n",
        "    )\n",
        "    \n",
        "    # Process files in project directory\n",
        "    for file_path in project_input_dir.iterdir():\n",
        "        if file_path.is_file() and file_path.name != \"metadata.json\":\n",
        "            try:\n",
        "                print(f\"Processing file: {file_path.name}\")\n",
        "                \n",
        "                # Determine file type\n",
        "                file_ext = file_path.suffix.lower()[1:]  # Remove the dot\n",
        "                \n",
        "                # Handle different file types\n",
        "                if file_ext in [\"pptx\"]:\n",
        "                    # Convert PowerPoint to PDF first (skipped for simplicity)\n",
        "                    # For now, we'll treat it as a regular file\n",
        "                    output_path = convert_to_markdown_file(\n",
        "                        input_value=str(file_path),\n",
        "                        kind=file_ext,\n",
        "                        use_llm=False,\n",
        "                        project_context=project_metadata\n",
        "                    )\n",
        "                    \n",
        "                elif file_ext in [\"pdf\"]:\n",
        "                    # Convert PDF to PNGs first, then to markdown\n",
        "                    png_output_dir = Path(\"./temp_pngs\")\n",
        "                    png_output_dir.mkdir(exist_ok=True)\n",
        "                    \n",
        "                    # Convert PDF to grouped PNGs\n",
        "                    pdf_to_grouped_pngs(\n",
        "                        pdf_path=str(file_path),\n",
        "                        out_dir=png_output_dir,\n",
        "                        dpi=200,\n",
        "                        group_size=1,\n",
        "                        grouping_prefix=\"page\",\n",
        "                        poppler_path=os.environ.get(\"POPPLER_PATH\")\n",
        "                    )\n",
        "                    \n",
        "                    # Process PNGs\n",
        "                    png_files = list(png_output_dir.glob(\"page_*.png\"))\n",
        "                    if png_files:\n",
        "                        # Process all PNGs and combine into single markdown\n",
        "                        combined_md = \"\"\n",
        "                        for i, png_path in enumerate(png_files, 1):\n",
        "                            res = image_converter.convert(str(png_path))\n",
        "                            combined_md += f\"\\n\\n# Page {i}\\n\\n\" + res.text_content.strip()\n",
        "                            \n",
        "                        # Write combined markdown with project context\n",
        "                        md_file_name = file_path.stem + \"_pages.md\"\n",
        "                        md_output_path = project_output_dir / md_file_name\n",
        "                        md_output_path.write_text(combined_md.strip(), encoding=\"utf-8\")\n",
        "                        print(f\"Wrote: {md_output_path}\")\n",
        "                        \n",
        "                        # Clean up temporary PNGs\n",
        "                        for png_file in png_files:\n",
        "                            png_file.unlink()\n",
        "                        png_output_dir.rmdir()\n",
        "                    \n",
        "                elif file_ext in [\"png\"]:\n",
        "                    # Process PNG directly\n",
        "                    res = image_converter.convert(str(file_path))\n",
        "                    output_path = project_output_dir / (file_path.stem + \".md\")\n",
        "                    output_path.write_text(res.text_content, encoding=\"utf-8\")\n",
        "                    print(f\"    Wrote: {output_path}\")\n",
        "                    \n",
        "                else:\n",
        "                    # Process other formats normally\n",
        "                    output_path = convert_to_markdown_file(\n",
        "                        input_value=str(file_path),\n",
        "                        kind=file_ext,\n",
        "                        use_llm=False,\n",
        "                        project_context=project_metadata\n",
        "                    )\n",
        "                    \n",
        "                # Move the original file to processed directory\n",
        "                # (We're just marking it as processed by writing the markdown)\n",
        "                print(f\"Successfully processed: {file_path.name}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path.name}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    print(f\"Completed processing project: {project_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_MfmhYvDrM0"
      },
      "source": [
        "# 2. Main Processing Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z1O8t9JETfj"
      },
      "source": [
        "### Process all projects with context from metadata.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPbr2C9uEfuM",
        "outputId": "1589af9b-d7b8-4291-dd35-d1de73296f1e"
      },
      "outputs": [],
      "source": [
        "def convert_to_markdown_file(\n",
        "    input_value: Union[str, Path],\n",
        "    kind: str,\n",
        "    use_llm: bool = False,\n",
        "    llm_client=None,\n",
        "    llm_model: Optional[str] = None,\n",
        "    llm_prompt: Optional[str] = None,\n",
        "    out_dir: Optional[Union[str, Path]] = None,\n",
        "    out_name: Optional[str] = None,\n",
        "    project_context: Optional[Dict] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Convert an input file or HTML string to Markdown using MarkItDown and write it to ./output_(file_type).\n",
        "\n",
        "    Parameters\n",
        "    - input_value\n",
        "      - For file-based kinds, pass a filesystem path.\n",
        "      - For 'html_string', pass a raw HTML string.\n",
        "    - kind: one of {'docx','xlsx','xls','html','htm','txt','log','csv','html_string'}\n",
        "    - use_llm: default False. If True, provide llm_client and llm_model.\n",
        "    - llm_client, llm_model, llm_prompt: forwarded to MarkItDown when use_llm=True\n",
        "    - out_dir: optional override of the output directory. Defaults to ./output_(group)\n",
        "    - out_name: optional base filename without extension. Defaults to input file stem when applicable.\n",
        "    - project_context: dict containing project metadata that gets added to markdown output\n",
        "\n",
        "    Returns\n",
        "    - Path to the written Markdown file.\n",
        "    \"\"\"\n",
        "    # 1) Normalize kind and choose default output directory bucket\n",
        "    k = kind.lower().strip()\n",
        "    allowed = {\"docx\", \"xlsx\", \"xls\", \"html\", \"htm\", \"txt\", \"log\", \"csv\", \"html_string\", \"png\", \"pptx\", \"pdf\"}\n",
        "    if k not in allowed:\n",
        "        raise ValueError(f\"kind must be one of {allowed}\")\n",
        "\n",
        "    if out_dir is None:\n",
        "        if k in {\"xlsx\", \"xls\"}:\n",
        "            out_dir = \"./output_xlsx\"\n",
        "        elif k in {\"html\", \"htm\", \"html_string\"}:\n",
        "            out_dir = \"./output_html\"\n",
        "        elif k in {\"txt\", \"log\"}:\n",
        "            out_dir = \"./output_txt\"\n",
        "        elif k == \"docx\":\n",
        "            out_dir = \"./output_docx\"\n",
        "        elif k == \"csv\":\n",
        "            out_dir = \"./output_csv\"\n",
        "        elif k in {\"png\", \"pptx\", \"pdf\"}:\n",
        "            out_dir = \"./output_images\"\n",
        "\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 2) Build MarkItDown converter\n",
        "    from markitdown import MarkItDown\n",
        "    if use_llm:\n",
        "        if llm_client is None or llm_model is None:\n",
        "            raise ValueError(\"use_llm=True requires llm_client and llm_model\")\n",
        "        converter = MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)\n",
        "    else:\n",
        "        converter = MarkItDown()\n",
        "\n",
        "    # 3) Convert depending on kind\n",
        "    if k == \"html_string\":\n",
        "        if not out_name:\n",
        "            raise ValueError(\"out_name is required when kind='html_string'\")\n",
        "        res = converter.convert_html(str(input_value))\n",
        "        base_name = out_name\n",
        "    else:\n",
        "        p = Path(input_value)\n",
        "        res = converter.convert(str(p))\n",
        "        base_name = out_name or p.stem\n",
        "\n",
        "    # 4) Add project context to beginning of Markdown output if provided\n",
        "    if project_context:\n",
        "        context_str = \"#### PROJECT CONTEXT\\n\"\n",
        "        for key, value in project_context.items():\n",
        "            context_str += f\"- **{key}:** {value}\\n\"\n",
        "        context_str += \"\\n\"\n",
        "        res.text_content = context_str + res.text_content\n",
        "        \n",
        "    # 5) Write markdown\n",
        "    out_path = out_dir / f\"{base_name}.md\"\n",
        "    out_path.write_text(res.text_content, encoding=\"utf-8\")\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def process_project(project_name: str):\n",
        "    \"\"\"\n",
        "    Process an entire project directory.\n",
        "    \n",
        "    Args:\n",
        "        project_name (str): Name of the project directory\n",
        "    \"\"\"\n",
        "    print(f\"Processing project: {project_name}\")\n",
        "    \n",
        "    # Get input and output paths\n",
        "    project_input_dir = INPUT_BASE_DIR / project_name\n",
        "    project_output_dir = OUTPUT_BASE_DIR / project_name\n",
        "    \n",
        "    # Create output directory\n",
        "    project_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Read project metadata\n",
        "    metadata_path = project_input_dir / \"metadata.json\"\n",
        "    project_metadata = {}\n",
        "    if metadata_path.exists():\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            project_metadata = json.load(f)\n",
        "    \n",
        "    # Initialize client for LLM-based conversions\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    image_converter = MarkItDown(\n",
        "        llm_client=client,\n",
        "        llm_model=LLM_MODEL,\n",
        "        llm_prompt=system_prompt\n",
        "    )\n",
        "    \n",
        "    # Process files in project directory\n",
        "    for file_path in project_input_dir.iterdir():\n",
        "        if file_path.is_file() and file_path.name != \"metadata.json\":\n",
        "            try:\n",
        "                print(f\"Processing file: {file_path.name}\")\n",
        "                \n",
        "                # Determine file type\n",
        "                file_ext = file_path.suffix.lower()[1:]  # Remove the dot\n",
        "                \n",
        "                # Handle different file types\n",
        "                if file_ext in [\"pptx\"]:\n",
        "                    # Convert PowerPoint to PDF first (skipped for simplicity)\n",
        "                    # For now, we'll treat it as a regular file\n",
        "                    output_path = convert_to_markdown_file(\n",
        "                        input_value=str(file_path),\n",
        "                        kind=file_ext,\n",
        "                        use_llm=False,\n",
        "                        project_context=project_metadata\n",
        "                    )\n",
        "                    \n",
        "                elif file_ext in [\"pdf\"]:\n",
        "                    # Convert PDF to PNGs first, then to markdown\n",
        "                    png_output_dir = Path(\"./temp_pngs\")\n",
        "                    png_output_dir.mkdir(exist_ok=True)\n",
        "                    \n",
        "                    # Convert PDF to grouped PNGs\n",
        "                    pdf_to_grouped_pngs(\n",
        "                        pdf_path=str(file_path),\n",
        "                        out_dir=png_output_dir,\n",
        "                        dpi=200,\n",
        "                        group_size=1,\n",
        "                        grouping_prefix=\"page\",\n",
        "                        poppler_path=os.environ.get(\"POPPLER_PATH\")\n",
        "                    )\n",
        "                    \n",
        "                    # Process PNGs\n",
        "                    png_files = list(png_output_dir.glob(\"page_*.png\"))\n",
        "                    if png_files:\n",
        "                        # Process all PNGs and combine into single markdown\n",
        "                        combined_md = \"\"\n",
        "                        for i, png_path in enumerate(png_files, 1):\n",
        "                            res = image_converter.convert(str(png_path))\n",
        "                            combined_md += f\"\\n\\n# Page {i}\\n\\n\" + res.text_content.strip()\n",
        "                            \n",
        "                        # Write combined markdown with project context\n",
        "                        md_file_name = file_path.stem + \"_pages.md\"\n",
        "                        md_output_path = project_output_dir / md_file_name\n",
        "                        md_output_path.write_text(combined_md.strip(), encoding=\"utf-8\")\n",
        "                        print(f\"Wrote: {md_output_path}\")\n",
        "                        \n",
        "                        # Clean up temporary PNGs\n",
        "                        for png_file in png_files:\n",
        "                            png_file.unlink()\n",
        "                        png_output_dir.rmdir()\n",
        "                    \n",
        "                elif file_ext in [\"png\"]:\n",
        "                    # Process PNG directly\n",
        "                    res = image_converter.convert(str(file_path))\n",
        "                    output_path = project_output_dir / (file_path.stem + \".md\")\n",
        "                    output_path.write_text(res.text_content, encoding=\"utf-8\")\n",
        "                    print(f\"    Wrote: {output_path}\")\n",
        "                    \n",
        "                else:\n",
        "                    # Process other formats normally\n",
        "                    output_path = convert_to_markdown_file(\n",
        "                        input_value=str(file_path),\n",
        "                        kind=file_ext,\n",
        "                        use_llm=False,\n",
        "                        project_context=project_metadata\n",
        "                    )\n",
        "                    \n",
        "                # Move the original file to processed directory\n",
        "                # (We're just marking it as processed by writing the markdown)\n",
        "                print(f\"Successfully processed: {file_path.name}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path.name}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    print(f\"Completed processing project: {project_name}\")\n",
        "\n",
        "\n",
        "def process_all_projects():\n",
        "    \"\"\"\n",
        "    Process all projects in the not_processed directory.\n",
        "    \"\"\"\n",
        "    print(\"Starting project processing...\")\n",
        "    \n",
        "    # Iterate through each project directory in not_processed\n",
        "    for project_dir in INPUT_BASE_DIR.iterdir():\n",
        "        if project_dir.is_dir():\n",
        "            process_project(project_dir.name)\n",
        "            \n",
        "    print(\"All projects processed!\")\n",
        "\n",
        "# Run the processing pipeline\n",
        "#process_all_projects()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
