{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7aKzN5PDTfE"
      },
      "source": [
        "# 0. Install if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_4TUKm2DDMbc",
        "outputId": "579a0d17-1afc-437f-b52a-14c3e30e4990"
      },
      "outputs": [],
      "source": [
        "%pip install \"markitdown[all]\" openai pdf2image pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports, basic definitions and option selections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\RAC62971\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from markitdown import MarkItDown\n",
        "from dotenv import load_dotenv\n",
        "from pdf2image import convert_from_path\n",
        "from typing import Dict, List, Optional, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load in the API key from the top-level .env file\n",
        "load_dotenv(Path.cwd().parent / \".env\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define the model we want to use to convert the PNGs into Markdown\n",
        "LLM_MODEL = \"gpt-5-mini\"\n",
        "\n",
        "# Read in the system prompts\n",
        "sys_prompt_detailed = (Path.cwd() / \"system_prompts\" / \"system_prompt_detailed.md\").read_text(encoding=\"utf-8\")\n",
        "sys_prompt_summarized = (Path.cwd() / \"system_prompts\" / \"system_prompt_summarized.md\").read_text(encoding=\"utf-8\")\n",
        "\n",
        "# Choose the system prompt you'd like to use. Detailed will attempt to keep as much of the original content\n",
        "# as possible, at the cost of speed and cost. Summarized will summarize much more of the content but it will\n",
        "# be fast and cost less to process the data\n",
        "sys_prompt_mode = \"detailed\" # can be 'detailed' or 'summarized'\n",
        "system_prompt = sys_prompt_detailed if sys_prompt_mode == \"detailed\" else sys_prompt_summarized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Markdown conversion function\n",
        "All file types except for PowerPoint are converted directory into Markdown. PowerPoints are first converted into a PDF, which is then converted into PNGs, and finally those PNGs are converted into Markdown.\n",
        "\n",
        "Allowed file types: \n",
        "* PowerPoint\n",
        "    - pptx\n",
        "* Word\n",
        "    - docx\n",
        "* Excel\n",
        "    - xlsx\n",
        "    - xls\n",
        "    - csv\n",
        "* Text\n",
        "    - txt\n",
        "    - pdf\n",
        "    - html\n",
        "    - htm\n",
        "    - html_string\n",
        "    - log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ALLLLLLLLLLLLLLLLLLLL OF THEMMMMMMMMMMMMMMMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_markdown_file(\n",
        "    input_value: Union[str, Path],\n",
        "    kind: str,\n",
        "    use_llm: bool = False,\n",
        "    llm_client=None,\n",
        "    llm_model: Optional[str] = None,\n",
        "    llm_prompt: Optional[str] = None,\n",
        "    out_dir: Optional[Union[str, Path]] = None,\n",
        "    out_name: Optional[str] = None,\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Convert an input file or HTML string to Markdown using MarkItDown and write it to ./output_(file_type).\n",
        "\n",
        "    Parameters\n",
        "    - input_value\n",
        "      - For file-based kinds, pass a filesystem path.\n",
        "      - For 'html_string', pass a raw HTML string.\n",
        "    - kind: one of {'docx','xlsx','xls','html','htm','txt','log','csv','html_string'}\n",
        "    - use_llm: default False. If True, provide llm_client and llm_model.\n",
        "    - llm_client, llm_model, llm_prompt: forwarded to MarkItDown when use_llm=True\n",
        "    - out_dir: optional override of the output directory. Defaults to ./output_(group)\n",
        "    - out_name: optional base filename without extension. Defaults to input file stem when applicable.\n",
        "\n",
        "    Returns\n",
        "    - Path to the written Markdown file.\n",
        "    \"\"\"\n",
        "    # 1) Normalize kind and choose default output directory bucket\n",
        "    k = kind.lower().strip()\n",
        "    allowed = {\"docx\", \"xlsx\", \"xls\", \"html\", \"htm\", \"txt\", \"log\", \"csv\", \"html_string\"}\n",
        "    if k not in allowed:\n",
        "        raise ValueError(f\"kind must be one of {allowed}\")\n",
        "\n",
        "    if out_dir is None:\n",
        "        if k in {\"xlsx\", \"xls\"}:\n",
        "            out_dir = \"./output_xlsx\"\n",
        "        elif k in {\"html\", \"htm\", \"html_string\"}:\n",
        "            out_dir = \"./output_html\"\n",
        "        elif k in {\"txt\", \"log\"}:\n",
        "            out_dir = \"./output_txt\"\n",
        "        elif k == \"docx\":\n",
        "            out_dir = \"./output_docx\"\n",
        "        elif k == \"csv\":\n",
        "            out_dir = \"./output_csv\"\n",
        "\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 2) Build MarkItDown converter\n",
        "    from markitdown import MarkItDown\n",
        "    if use_llm:\n",
        "        if llm_client is None or llm_model is None:\n",
        "            raise ValueError(\"use_llm=True requires llm_client and llm_model\")\n",
        "        converter = MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)\n",
        "    else:\n",
        "        converter = MarkItDown()\n",
        "\n",
        "    # 3) Convert depending on kind\n",
        "    if k == \"html_string\":\n",
        "        if not out_name:\n",
        "            raise ValueError(\"out_name is required when kind='html_string'\")\n",
        "        res = converter.convert_html(str(input_value))\n",
        "        base_name = out_name\n",
        "    else:\n",
        "        p = Path(input_value)\n",
        "        res = converter.convert(str(p))\n",
        "        base_name = out_name or p.stem\n",
        "\n",
        "    # 4) Write markdown\n",
        "    out_path = out_dir / f\"{base_name}.md\"\n",
        "    out_path.write_text(res.text_content, encoding=\"utf-8\")\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_MfmhYvDrM0"
      },
      "source": [
        "# 1. Convert PDF -> PNGs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-m4uQ17ERqT"
      },
      "source": [
        "Goes through a PDF and converts each page into an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the POPPLER_PATH environment variable\n",
        "os.environ[\"POPPLER_PATH\"] = r\"C:\\Users\\RAC62971\\Downloads\\poppler-25.07.0\\Library\\bin\"\n",
        "\n",
        "def pdf_to_grouped_pngs(\n",
        "    pdf_path: Union[str, Path],\n",
        "    out_dir: Union[str, Path],\n",
        "    dpi: int = 200,\n",
        "    group_size: int = 1,\n",
        "    grouping_prefix: str = \"grouping\",\n",
        "    fmt: str = \"PNG\",\n",
        "    poppler_path: Optional[Union[str, Path]] = None,\n",
        "    first_page: Optional[int] = None,\n",
        "    last_page: Optional[int] = None,\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Convert a PDF into per-page images and group them into subfolders.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pdf_path : str | Path\n",
        "        Path to the input PDF, e.g. r\"C:\\\\...\\\\my.pdf\".\n",
        "    out_dir : str | Path\n",
        "        Output directory root where grouped folders will be created.\n",
        "    dpi : int, default 200\n",
        "        Render DPI for rasterization.\n",
        "    group_size : int, default 1\n",
        "        Number of pages per group folder. For example, 2 will place pages\n",
        "        1 and 2 into 'grouping_1', pages 3 and 4 into 'grouping_2', etc.\n",
        "    grouping_prefix : str, default \"grouping\"\n",
        "        Folder name prefix for each group.\n",
        "    fmt : str, default \"PNG\"\n",
        "        Image format to write. Common options are \"PNG\" and \"JPEG\".\n",
        "    poppler_path : str | Path | None\n",
        "        Path to Poppler bin directory on Windows if not on PATH.\n",
        "        Example: r\"C:\\\\tools\\\\poppler-24.08.0\\\\Library\\\\bin\"\n",
        "    first_page : int | None\n",
        "        Optional first page to convert (1-indexed).\n",
        "    last_page : int | None\n",
        "        Optional last page to convert (inclusive).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, List[str]]\n",
        "        Mapping of group folder name to list of saved image paths (strings).\n",
        "    \"\"\"\n",
        "    pdf_path = Path(pdf_path)\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if group_size < 1:\n",
        "        raise ValueError(\"group_size must be >= 1\")\n",
        "\n",
        "    images = convert_from_path(\n",
        "        str(pdf_path),\n",
        "        dpi=dpi,\n",
        "        first_page=first_page,\n",
        "        last_page=last_page,\n",
        "        poppler_path=str(poppler_path) if poppler_path else None,\n",
        "    )\n",
        "\n",
        "    saved: Dict[str, List[str]] = {}\n",
        "    for i, img in enumerate(images, start=1 if not first_page else first_page):\n",
        "        # Compute 1-indexed group index\n",
        "        group_idx = (i - (first_page or 1)) // group_size + 1\n",
        "        group_dir = out_dir / f\"{grouping_prefix}_{group_idx}\"\n",
        "        group_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        page_basename = f\"page_{i:03}.{fmt.lower()}\"\n",
        "        out_path = group_dir / page_basename\n",
        "        img.save(out_path, fmt)\n",
        "        saved.setdefault(f\"{grouping_prefix}_{group_idx}\", []).append(str(out_path))\n",
        "\n",
        "    return saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'grouping_1': ['output_pngs\\\\grouping_1\\\\page_001.png',\n",
              "  'output_pngs\\\\grouping_1\\\\page_002.png'],\n",
              " 'grouping_2': ['output_pngs\\\\grouping_2\\\\page_003.png',\n",
              "  'output_pngs\\\\grouping_2\\\\page_004.png'],\n",
              " 'grouping_3': ['output_pngs\\\\grouping_3\\\\page_005.png',\n",
              "  'output_pngs\\\\grouping_3\\\\page_006.png'],\n",
              " 'grouping_4': ['output_pngs\\\\grouping_4\\\\page_007.png',\n",
              "  'output_pngs\\\\grouping_4\\\\page_008.png'],\n",
              " 'grouping_5': ['output_pngs\\\\grouping_5\\\\page_009.png',\n",
              "  'output_pngs\\\\grouping_5\\\\page_010.png']}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_to_grouped_pngs(\n",
        "    pdf_path=r\".\\input_data\\V2 - one-pagers with summaries- HRI-OH-99P Project Descriptions (1).pdf\",\n",
        "    out_dir=r\".\\output_pngs\",\n",
        "    dpi=200,\n",
        "    group_size=2,\n",
        "    grouping_prefix=\"grouping\",\n",
        "    poppler_path=os.environ[\"POPPLER_PATH\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBzF54RBEauR"
      },
      "source": [
        "# 2. Convert PNGs -> Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PNGs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPbr2C9uEfuM",
        "outputId": "1589af9b-d7b8-4291-dd35-d1de73296f1e"
      },
      "outputs": [],
      "source": [
        "PNG_DIR = Path(\"./output_pngs\")\n",
        "OUT_DIR = Path(\"./output_markdown\")\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "image_converter = MarkItDown(\n",
        "    llm_client=client,\n",
        "    llm_model=LLM_MODEL,\n",
        "    llm_prompt=system_prompt\n",
        ")\n",
        "\n",
        "def _grouping_index(p: Path) -> int:\n",
        "    # Extract the integer from \"grouping_{number}\"\n",
        "    m = re.search(r\"grouping_(\\d+)$\", p.name)\n",
        "    return int(m.group(1)) if m else 0\n",
        "\n",
        "def _sorted_imgs(imgs):\n",
        "    # Sort by any integer in filename, else lexicographic\n",
        "    def key_fn(p: Path):\n",
        "        m = re.findall(r\"\\d+\", p.stem)\n",
        "        return (int(m[-1]) if m else 0, p.name.lower())\n",
        "    return sorted(imgs, key=key_fn)\n",
        "\n",
        "# Ensure OUT_DIR exists\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Find all grouping_* directories at first level under PNG_DIR\n",
        "grouping_dirs = sorted([d for d in PNG_DIR.iterdir() if d.is_dir() and d.name.startswith(\"grouping_\")],\n",
        "                    key=_grouping_index)\n",
        "\n",
        "if not grouping_dirs:\n",
        "    print(f\"No grouping_* directories found in {PNG_DIR.resolve()}\")\n",
        "\n",
        "for tdir in grouping_dirs:\n",
        "    grouping_num = _grouping_index(tdir)\n",
        "    imgs = _sorted_imgs(list(tdir.glob(\"*.png\")))\n",
        "    if not imgs:\n",
        "        print(f\"Skipping {tdir.name} because it has no PNGs\")\n",
        "        continue\n",
        "\n",
        "    per_image_md = []\n",
        "    for i, img_path in enumerate(imgs, start=1):\n",
        "        try:\n",
        "            res = image_converter.convert(str(img_path))\n",
        "            per_image_md.append(f\"\\n\\n# Slide {i}\\n\\n\" + res.text_content.strip())\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not per_image_md:\n",
        "        print(f\"No markdown produced for {tdir.name}\")\n",
        "        continue\n",
        "\n",
        "    combined_image_md = \"\".join(per_image_md).strip()\n",
        "\n",
        "    # Write to OUT_DIR/grouping_{number}/<BASE_NAME>_grouping_{number}_{with|no}_llm.md\n",
        "    out_grouping_dir = OUT_DIR / f\"grouping_{grouping_num}\"\n",
        "    out_grouping_dir.mkdir(parents=True, exist_ok=True)\n",
        "    suffix = \"processed\"\n",
        "    combined_path = out_grouping_dir / f\"grouping_{grouping_num}.md\"\n",
        "    combined_path.write_text(combined_image_md, encoding=\"utf-8\")\n",
        "    print(\"Wrote:\", combined_path.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
